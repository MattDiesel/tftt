
\documentclass[twoside]{IIBproject}
\usepackage[utf8] {inputenc}

% \usepackage{fancyhdr}
% \fancyhf{}
% \renewcommand{\headrulewidth}{0pt}
% \fancyfoot[LE,RO]{\thepage}

\usepackage[bottom]{footmisc}
\usepackage{setspace,titlesec}
\onehalfspacing
\newcommand{\sectionbreak}{\clearpage}

\widowpenalties 1 10000
\raggedbottom

\usepackage{url}
\usepackage[hidelinks,breaklinks=true]{hyperref}

\def\CC{{C\nolinebreak[4]\hspace{-.05em}\raisebox{.4ex}{\tiny\bf ++}}}

\usepackage{graphicx,float,epstopdf,subcaption}
\graphicspath{{method/}{method/gen}{results/}{results/gen}}

\makeatletter
\def\input@path{{method/}{method/gen}{results/}{results/gen}}
\makeatother

\usepackage{booktabs,threeparttable,tabularx,multirow}

\usepackage{tikz,fp,tikz-qtree}
\usetikzlibrary{positioning,calc,external}
% \tikzexternalize

\definecolor{colorA} {rgb} {0.1686, 0.5137, 0.7294}
\definecolor{colorB} {rgb} {0.9922, 0.6824, 0.3804}
\definecolor{colorC} {rgb} {0.4706, 0.6745, 0.4392}
\definecolor{colorD} {rgb} {0.8431, 0.0980, 0.1137}

\usepackage{amsmath,amsfonts,bm,physics}
\newcommand{\vect} [1] {\bm{#1}}
\newcommand{\mat} [1]{\mathbf{#1}}
\newcommand{\dra}{\dashrightarrow}
\newcommand{\dla}{\dashleftarrow}
\newcommand{\acc}{{\mkern 0.5mu\cdot\mkern 0.5mu}}
\newcommand{\bigO} [1]{\mathcal{O}(#1)}
\numberwithin{figure}{section}

\usepackage[section]{algorithm}
\usepackage{algpseudocode}
\algnewcommand\algorithmicsend{\textbf{send}}
\algnewcommand\Send{\State\algorithmicsend\ }
\algnewcommand\algorithmicrecv{\textbf{recv}}
\algnewcommand\Recv{\State\algorithmicrecv\ }
\algnewcommand\algorithmicgather{\textbf{gather}}
\algnewcommand\Gather{\State\algorithmicgather\ }
\algnewcommand\algorithmicscatter{\textbf{scatter}}
\algnewcommand\Scatter{\State\algorithmicscatter\ }
\algnewcommand\algorithmicforeach{\textbf{for \ each}}
\algblockdefx[ForEach]{ForEach}{EndFor}
[1][]{\algorithmicforeach\ #1}
{\textbf{end\ for }}

\usepackage[cache=true,outputdir=tmp]{minted}
\usepackage{sourcecodepro}
\usemintedstyle{vs}

\usepackage[backend=biber,style=ieee,sorting=none]{biblatex}

\appto{\biburlsetup}{\renewcommand*{\UrlFont}{\raggedright\scriptsize\ttfamily}}
\DeclareFieldFormat*{formaturl}{\newline #1}
\DeclareFieldFormat*{hyperlink}{$[\text{Online}]$~~{\UrlFont \url{#1}} \nopunct}
\renewbibmacro*{url}{%
\iffieldundef{url}{}{%
\printtext[formaturl]{%
    \printfield[hyperlink]{url}}}}

\addbibresource{refs.bib}

\usepackage[toc,page]{appendix}


\begin{document}


\date{31st May 2017}
\author{Matt Diesel (md639)}
\supervisor{Dr. Jie Li}
\title{Parallel Adaptation of Orthotree Meshes}

\pagestyle{empty}
\maketitle

\thispagestyle{empty}
\renewcommand{\abstractname}{Technical Abstract}
\begin{abstract}
\input{technical-abstract.txt}
\end{abstract}

\newpage
\setcounter{tocdepth}{2}
\tableofcontents
\newpage
\pagestyle{plain}


\section{Introduction} % (fold)
    \label{sec:intro}

    Numerical simulations are a vital tool in the understanding and modelling of fluid systems. The ability to analyse processes without the financial and temporal costs of producing physical tests not only drives down research and development costs but also makes it possible to automate the optimisation of systems. Fluid simulations continue to be limited by computational resources however, making many problems inhibiting slow to be of any practical use. As a result, improving the methods used in Computational Fluid Dynamics remains a key area of research.

    Adaptive Mesh Refinement (AMR) methods improves the efficiency of numeric methods by recognising that not all areas of a simulation require finely grained meshes. This allows for greater spatial resolution and significant reductions in the memory and processing requirements of meshes. AMR methods have been applied to structured meshes, where every cell has a uniform geometry, as well as unstructured meshes that while more complex can be tailored to a specific problem's geometry. 

    High Performance Computing (HPC) in the last decade has been dominated by cluster based computing, taking over from specialised Massively Parallel Processing machines \cite{top500}. Clusters make use of distributed computing methods with off the shelf components, making them a cost effective and robust solution for HPC. The scalability of software designed to run on clusters is another benefit, giving rise to a marketplace for hiring cluster computation time. Compared to other methods of HPC, the interprocess communication on clusters is much slower than system memory. As a result, new methods must be developed to adapt algorithms and data structures for distributed computing.

    This project demonstrates that a particular method of structured AMR can be implemented in a suitable manner for use on clusters. The combination of AMR and distributed computing features the benefits of both methods. 

    A \CC~ library was developed from scratch and is available online at \cite{me17}. Initially based on methods developed previously by others outlined in Section~\ref{sec:existingmethods}, the functionality is extended in Section~\ref{sec:method} with new methods suitable for distributed computing. The additions to the structure are then analysed in Section~\ref{sec:results}. A number of proposals are made for future additions to the library in Section~\ref{sec:future-work}. 


\section{Implementation of Prior Work}
    \label{sec:existingmethods}

    \subsection{Orthotree Fundamentals} % (fold)
        \label{sec:orthotree}

        Orthotopes are defined by \cite{coxeter73} as the N-dimensional extrapolation of a rectangle. The term is used here to generalise between rectangles in the two-dimensional case and cuboids in the three-dimensional case.

        An orthotree is a tree structure where each cell is orthotopic and its children are evenly sized similar orthotopes. For this project, the two-dimensional case (known as a quadtree) was implemented and examined in detail. All the methods are kept general however, to allow adaptation to the three-dimensional octree. 

        Cells are referred to in this document using a calligraphic typed letter, such as $\mathcal{C}$. Properties of the cell use dot member access notation, for example $\mathcal{C}\acc\textproc{data}$ is the data associated with the cell $\mathcal{C}$. This is implemented using an abstraction class \texttt{CellRef}, with the corresponding method names given in Appendix~\ref{sec:appendix-headers} Listing~\ref{src:cellref}.


        \subsubsection{Layer Links} % (fold)
            \label{sec:orthotree-layers}

            A cells parent is stored as a reference $\mathcal{C}\acc\textproc{parent}$. The children of a cell $\mathcal{C}$ are accessed as a list $\mathcal{C}\acc\vect{\mathcal{K}}=\{\mathcal{K}_0,\mathcal{K}_1,\cdots,\mathcal{K}_n\}$, with the child count $n=2^\mathrm{DIM}$.

            \begin{figure}[!htbp]
                \centering
                \input{layerlinks}
                \caption{Three layers of the tree, showing a cell $\mathcal{C}$, its parent $\mathcal{C}\acc\textproc{parent}$, and its children $\mathcal{C}\acc\vect{\mathcal{K}}$.}
                \label{fig:ftt-layerlinks}
            \end{figure}

            Children are indexed using one bit per dimension, with increasing dimension number corresponding to increasing bit significance as shown in Figure~\ref{fig:childnum}.

            \begin{figure} [!htbp]
                \centering
                \begin{subfigure}[b]{.3\textwidth}
                    \centering
                    \tikzset{external/export next=false}
                    \begin{tikzpicture}[every node/.append style={
                        draw,line width=0.1mm,inner sep=0, minimum size=1cm-0.1mm}]
                        \node at (0.5,0.5) {0};
                        \node at (1.5,0.5) {1};
                        \node at (0.5,1.5) {2};
                        \node at (1.5,1.5) {3};

                        \begin{scope}[xshift=3cm,every node/.append style={draw=none}]
                            \draw[->] (0,0) -- (1,0) node[anchor=west,xshift=-1mm] {$x$};
                            \draw[->] (0,0) -- (0,1) node[anchor=south,yshift=-1mm] {$y$};
                        \end{scope}

                        \node[draw=none] at (0, -0.5cm) {};
                    \end{tikzpicture}
                    \caption{Quadtree}
                    \label{fig:childnum-2d}
                \end{subfigure}\hspace{2cm}%
                \begin{subfigure}[b]{.3\textwidth}
                    \centering
                    \tikzset{external/export next=false}
                    \begin{tikzpicture}[every node/.append style={
                        draw,line width=0.1mm,inner sep=0, minimum size=1cm-0.1mm}]
                        \begin{scope}[ % x,y, z=1
                            yshift=2cm,xshift=0,every node/.append style={
                            yslant=-0.5,xslant=1},yslant=-0.5,xslant=1]
                            \node at (0.5,0.5) {4};
                            \node at (1.5,0.5) {5};
                            \node at (0.5,1.5) {6};
                            \node at (1.5,1.5) {7};
                        \end{scope}
                        \begin{scope}[ % x,z y=0
                            yshift=0,every node/.append style={
                            yslant=-0.5,xslant=0},yslant=-0.5,xslant=0]
                            \node at (0.5,0.5) {0};
                            \node at (1.5,0.5) {1};
                            \node at (0.5,1.5) {4};
                            \node at (1.5,1.5) {5};
                        \end{scope}
                        \begin{scope}[ % y,z, x=1
                            yshift=-1cm,xshift=2cm,every node/.append style={
                            yslant=0.5,xslant=0},yslant=0.5,xslant=0]
                            \node at (0.5,0.5) {1};
                            \node at (1.5,0.5) {3};
                            \node at (0.5,1.5) {5};
                            \node at (1.5,1.5) {7};
                        \end{scope}
                        \begin{scope}[xshift=5cm,every node/.append style={draw=none}]
                            \draw[->] (0,0) -- (0.8,-0.4) node[anchor=west,xshift=-1mm,yshift=-2mm] {$x$};
                            \draw[->] (0,0) -- (0.8,0.4) node[anchor=south west,xshift=-1mm,yshift=-4mm] {$y$};
                            \draw[->] (0,0) -- (0,1) node[anchor=south,yshift=-1mm] {$z$};
                        \end{scope}
                    \end{tikzpicture}
                    \caption{Octree}
                    \label{fig:childnum-3d}
                \end{subfigure}%
                \caption{Child numbering for the two common orthotree cases. It can be seen that a step in a direction $d$ equates to a change in child index of $2^d$}
                \label{fig:childnum}
            \end{figure}

        % subsubsection orthotree-layers (end)


        \subsubsection{Refinement} %(fold)
            \label{sec:orthotree-refine}

            The tree is refined depending on the conditions of the problem being solved. Figure~\ref{fig:layeredtree} shows a trivial case refining to a simple line geometry. At each level, cells are refined if and only if the line overlaps the cell at any point. 

            The cells without children form the finest level of the mesh. These are known as the leaves of the tree $\mathbb{L}$, and size of the tree is taken to be the number of leaves $\abs{\mathbb{L}}$. Parent cells aren't used in the numeric methods applied to the mesh, and since they do not impact the computational time of numeric operations are not included in the tree size. 

            \begin{figure} [htb]
                \input{method/layeredtree}
                \caption{4 levels of a quadtree refined to a line shown in blue. If a cell is not a leaf, its children are shown in orange.}
                \label{fig:layeredtree}
            \end{figure}

        % subsubsection orthotree-refine (end)


        \subsubsection{Refinement Propagation} % (fold)
            \label{sec:orthotree-refprop}

            The selection method used for Figure~\ref{fig:layeredtree} is based on the assumption that the cells of interest are only those directly on the line. In practice, the refinement levels should be spread to limit the number of combinations of cell boundaries and smooth the output. One simple method is to propagate refinement levels such that there are no cells within a parameter $P$ cell widths in the axis directions that are more than one level apart. Examples of using refinement propagation at three values for $P$ are presented in Figure~\ref{fig:refprop}.

            \expandafter\newcommand\csname countL(0) \endcsname{280}
            \expandafter\newcommand\csname countL(1) \endcsname{452}
            \expandafter\newcommand\csname countL(2) \endcsname{604}
            \newcommand{\getCount} [1]{\csname countL(#1) \endcsname}

            \begin{figure} [!htbp]
                \centering
                \foreach \i in {0,1,2} {
                    \begin{subfigure}{.3\textwidth}
                        \centering
                        \begin{tikzpicture}
                            \draw[domain=0:3.8,smooth,variable=\x,colorA, thick] plot ({\x},
                                {0.3 + 6.189086*\x - 6.682936*\x*\x + 2.481516*\x*\x*\x - 0.2852701*\x*\x*\x*\x});
                            \input{method/gen/mesh-t\i}
                        \end{tikzpicture}
                        \caption{\\ $P=\i$ \qquad $\ \ \abs{\mathbb{L}}=\getCount{\i}$}
                        \label{fig:refprop-t\i}
                    \end{subfigure}%
                }
                \caption{Meshes for various refinement propagation levels $P$ to the example line geometry. In all cases the maximum refinement level is $5$, giving an equivalent uniform mesh cell count of $1024$ cells.}
                \label{fig:refprop}
            \end{figure}

            More complex schemes are possible, such as including the corners as suggested in \cite{pop03}, or using a circular kernel to spread the refinement level in a method similar to the smoothing used in image processing. Whilst these would produce better results if a single point were to be refined, it is assumed the geometry itself is smooth and so the simpler orthogonal direction propagation method is sufficient. 

            The case $P=1$ is referred to in other literature as Two-to-One Balancing, as a cell has no neighbours more than twice its size. This is the minimum propagation level the numeric methods written for this project will work on. Since the term balancing is used to refer to parallel load balancing in this report, this term will be avoided, and "refinement propagation" used in preference as a more general term.

        % subsubsection orthotree-refprop (end)

    % subsection orthotree (end)


    \subsection{Fully Threaded Trees} % (fold)
        \label{sec:ftt}

        The use of orthotree structures in Adaptive Mesh Routines (AMR) was proposed by Khokhlov in \cite{Khokhlov98}. To tailor them towards solving the differential equations in fluid problems, his implementation included storing the set of neighbours $\mathcal{C}\acc\vect{\mathcal{N}}$ for each cell $\mathcal{C}$ as shown for a one-dimensional tree in Figure~\ref{fig:ftt-neighbours}. This allows $\bigO{1}$ lookup compared to a possible $\bigO{\log n}$ lookup using tree traversal. Khokhlov termed the tree with the neighbour pointers a Fully Threaded Tree (FTT) structure.

        \begin{figure}[!htbp]
            \centering
            \input{method/ftttree}
            \caption{A flattened tree showing neighbour links between cells in orange}
            \label{fig:ftt-neighbours}
        \end{figure}

        In \cite{Khokhlov98}, an optimisation is presented to reduce the memory overhead introduced storing neighbour pointers by noting that for the children of a cell, half the neighbours are also children of the same cell. By storing groups of children together in an ortho\footnote{Referred to as a quad in two-dimensions and octo in three-dimensions.} the memory requirement for storing neighbour links is almost halved. This is implemented with the addition of the \texttt{TreeGroup} structure outlined in Appendix~\ref{sec:appendix-headers} Listing~\ref{src:treegroup}. 

        Optimisation details, such as storing cells in their groups, is abstracted over by performing most operations through the cell reference class. Regardless of whether a neighbour is a sibling of the cell or not, they form part of the set of neighbours $\mathcal{C}\acc\vect{\mathcal{N}}$. 

        For this implementation, the cell structures store their own index. Since the layout of the group structure is known, this is sufficient to calculate the offset to the start of the group. Other implementations, such as that used by \cite{Yung2010}, rely on alignment of the groups in order to perform the same calculation. That approach has some merit, but forces the memory manager to align the groups to large intervals for negligible saving\footnote{The memory saving for this implementation happens to be zero. The structure was already being padded to an 8 byte boundary, and the index added nothing to the allocated size. }, and relies on behaviour that is not guaranteed by the \CC~standard.

    % subsection ftt (end)


    % \subsection{Poisson Equation Solver} % (fold)
    %     \label{sec:poissonsolver}

    % % subsection poissonsolver (end)


    \subsection{Poisson Neighbourhoods} % (fold)
        \label{sec:poissonneighbours}

        To solve a finite difference equation on the adaptive mesh, interpolation is required in cases where the level of adjacent cells do not match. It is possible to move the expensive interpolation operation outside of the tight solver loop by instead storing a list of cells required along with the coefficient they would have been scaled by using direct interpolation. This list of cells is known as the poisson neighbourhood for a cell $\mathcal{C}$ and is represented by the vector $\mathcal{C}\acc\vect{\mathcal{P}}$. The respective neighbour coefficients are stored in the vector $\mathcal{C}\acc\vect{\beta}$. Each cell also requires a central coefficient $\mathcal{C}\acc\alpha$.

        More generally, the set $\mathcal{C}\acc\vect{\mathcal{P}}$ are the cells whose data the cell $\mathcal{C}$ depends on. This dependency neighbourhood is an important property that is made use of in later algorithms. The determining the of neighbourhood is abstracted to Function~\ref{fun:CalcPoisCoefs} and the implementation of mesh structure methods remains independent of the order of the finite difference solver, or the use of forward and backward instead of central differences.

        \begin{equation}
            \label{fun:CalcPoisCoefs}
            \textproc{CalcPoisCoefs}(\mathcal{C}) \mapsto \{ \vect{\mathcal{P}}, \vect{\beta}, \alpha \}
        \end{equation}

        Calculating the coefficients for the different cases is explored in detail by Yung in \cite{Yung2010} and Popinet in \cite{pop03}.  

    % subsection poissonneighbours (end)


    \subsection{Relaxation} % (fold)
        \label{sec:relaxation}

        Poisson's equation $\laplacian{\Phi}=f(\mathcal{C})$ can be solved by relaxation for a function $f$ that is constant during the relaxation. Every cell in the tree is "relaxed" once per iteration, converging on the final solution. 

        Successive Over-Relaxation (SOR) is a more robust numeric technique that smooths changes to cell data according to a relaxation factor $\Omega \in (0,2]$, to dampen oscillations in values between successive iterations. This accelerates convergence of high frequency components. A value of $\Omega=1$ gives no over-relaxation. 

        A new value for the data of the cell $\phi$ is calculated from the poisson neighbourhood using Equation~\ref{equ:relax-cell}. The derivation is given by Yung in \cite{Yung2010}.

        \begin{equation}
            \phi = \frac{ \left( \sum\limits_n \mathcal{C}\acc\beta_n \times \mathcal{C}\acc\mathcal{P}_n\acc\textproc{data} \right)-f(\mathcal{C})} { \mathcal{C}\acc\alpha }
            \label{equ:relax-cell}
        \end{equation}

        The new value is then applied to the cell, using the relaxation factor. 

        \begin{equation}
            \mathcal{C}\acc\textproc{data} = \Omega\phi + (1-\Omega)\times\mathcal{C}\acc\textproc{data}
        \end{equation}

        Cell data does not need to be applied to the entire tree at the same time. Once a value has been updated, it can be used in the relaxation of the neighbouring cells for the remainder of the iteration. 

    % subsection relaxation (end)


    \subsection{Residual Calculation} % (fold)
        \label{sec:residual}

        The work out whether the solver has converged, the relaxation method from before is checked by comparing the left and right hand sides of the poisson equation. The error between the two is called the residual $\eta$ and is given in Equation~\ref{equ:residual}.

        \begin{equation}
            \eta = \left( \sum\limits_n \mathcal{C}\acc\beta_n \times \mathcal{C}\acc\mathcal{P}_n\acc\textproc{data} \right)
             - \mathcal{C}\acc\alpha \times \mathcal{C}\acc\textproc{data}
             -f(\mathcal{C}) 
             \label{equ:residual}
        \end{equation}

        Convergence is obtained if all residuals are below a set point $\eta_c$. 

    % subsection residual (end)


    \subsection{Distributed Computing} % (fold)
        \label{sec:computing}

        The complete set of processes is called the world $\mathbb{W}$. Processes are identified by their zero-based rank - an integer $p \in [0;W)$ where $W=\abs{\mathbb{W}}$ is the total number of processes. 

        \subsubsection{MPI} % (fold)
            \label{sec:mpi}

            Message Passing Interface (MPI) is a library specification for interprocess communications in high-performance distributed computing \cite{mpi94}. The MPI library handles the starting of multiple copies of the same code in parallel, and provides interfaces for both point-to-point communication between two processes as well as collective operations over a set of processes. There exist several general implementations of the MPI standard for personal computing, whilst large cluster supercomputers often provide specialised implementations.

            The point-to-point operations are $\algorithmicsend\ \vect{X} \dra p$ and $\algorithmicrecv\ \vect{X} \dla p$ to send/receive data $\vect{X}$ to/from a foreign process $p$. In practice these cover a range of methods including synchronous and asynchronous transfer. In cases where the size of $\vect{X}$ is dynamic a skeleton of the structure is sent first before the data to allow the recipient to allocate the destination memory block. 

            The collective operations are $\algorithmicscatter\ \vect{X} \dra$ and $\algorithmicgather\ \vect{X} \dla \eval{x}_{p}$ where $\eval{x}_p$ is some function $x$ when evaluated on process $p$. Data scattered to the world is received using the same $\algorithmicrecv$ function as a point-to-point operation. Likewise the point-to-point $\algorithmicsend$ function is used for a gather operation.

            MPI abstracts the interface, and processes do not need to be running on the same machine, or even the same type of machine, as long as the interface is kept consistent. This make it highly scalable, as the same code used to run four processes on a single machine can then be used to run on a large cluster. 

            In this project, the Boost.MPI bindings from \cite{boost16} are used to access the MPI library. 

        % subsubsection mpi (end)


        \subsubsection{Load Balancing} % (fold)
            \label{sec:loadbalancing}

            For many distributed algorithms, all processes must be limited to run at the same speed as the slowest process. For the numeric methods used in this project, every process has to finish an iteration before the whole world can progress onto the next. Therefore, the maximum speed of the system as a whole would be gained by a uniform distribution of iteration times. In computing terms, this result is "load balancing", with a uniform distribution of iteration run-times being the optimal perfectly balanced load. 

        % subsubsection loadbalancing (end)

    % subsection computing (end)

% section intro (end)


\section{Method} % (fold)
    \label{sec:method}

    \subsection{Threaded FTT} % (fold)
        \label{sec:tftt}

        To distribute the $N$-dimensional orthotree onto a set of $W$ processes, it makes sense to flatten the tree into a one dimensional set of leaves $\mathbb{L}$, which can then be sliced evenly. In computing terms, the one-dimensional path is the ``thread'' through the structure. 

        Two properties $\mathcal{C}\acc\textproc{prev}$ and $\mathcal{C}\acc\textproc{next}$ for each cell are added, to form a doubly linked list through the leaves of the tree. The tree itself stores a link to the first and last leaves in the tree. This is shown in Figure~\ref{fig:tftt-flattree} for a one-dimensional tree with the leaves ordered from left to right. 

        \begin{figure}[!htbp]
            \centering
            \input{method/threadtree}
            \caption{A one-dimensional tree structure with nodes $\bullet$ and leaves $\square$. The double links through the leaves of the tree are shown in orange.}
            \label{fig:tftt-flattree}
        \end{figure}

        To achieve this in higher dimensions requires a Space Filling Curve (SFC). SFCs are curves filling a domain with a single continuous line \cite{bader2013}. 


        \subsubsection{Refinement and Coarsening} % (fold)
            \label{sec:tftt-refine}

            For simplicity, an additional constraint is imposed that the curve must not leave and re-enter a cell. This rules out some classes of SFC such as the Peano curve. Whilst it would be possible to implement such SFCs on a single processor, keeping local will allow subsections of the tree to change without knowledge of the full curve. This constraint is allows for the trivial implementation of  an additional pair of properties; the first and last children of a cell $C$ in the local curve. These are accessed as $\mathcal{C}\acc\textproc{firstChild}$ and $\mathcal{C}\acc\textproc{lastChild}$ respectively.

            Refinement or coarsening of cells must only change the local curve, analogous to insertion and deletion operations on the list as shown by Algorithms~\ref{alg:sfc-coarsen} and~\ref{alg:sfc-refine}.

            \begin{algorithm}[!htbp]
                \caption{Modifying the curve when coarsening the cell $\mathcal{C}$}
                \label{alg:sfc-coarsen}

                \begin{algorithmic}
                    \State $\mathcal{C}\acc\textproc{firstChild}\acc\textproc{prev}\acc\textproc{next} \Rightarrow \mathcal{C}$
                    \State $\mathcal{C}\acc\textproc{lastChild}\acc\textproc{next}\acc\textproc{prev} \Rightarrow \mathcal{C}$
                \end{algorithmic}
            \end{algorithm}

            \begin{algorithm}[!htbp]
                \caption{Modifying the curve when refining the cell $\mathcal{C}$}
                \label{alg:sfc-refine}

                \begin{algorithmic}
                    \Require {The internal curve of $C$.}
                    \Statex
                    \State $\mathcal{C}\acc\textproc{prev}\acc\textproc{next} \Rightarrow \mathcal{C}\acc\textproc{firstChild}$
                    \State $\mathcal{C}\acc\textproc{next}\acc\textproc{prev} \Rightarrow \mathcal{C}\acc\textproc{lastChild}$
                \end{algorithmic}
            \end{algorithm}

        % subsubsection tftt-refine (end)

        \subsubsection{Defining Space Filling Curves} % (fold)
            \label{sec:tftt-sfc}

            Since the tree is constructed top down, this approach of the previous section implies that defining the curve order of children of a cell is sufficient to describe the curve of the tree. This approach differs from previous uses of SFCs on orthotrees in that it stores the thread through the tree rather than using the SFC definition to iterate over it as \cite{bader2013} and others have done.

            Likewise the notation must differ slightly from the commonly used rewrite systems such as the Lindenmayer system [cite]. The curves are defined by a sequence $S$ of child indices using the ordering in Figure~\ref{fig:childnum}.

            The simplest case is a Morton curve given in Equation~\ref{equ:sfc-mort2d}, which equates to the standard child order. Graphically represented, Figure~\ref{fig:sfc-morton} shows the change in the curve with progressive levels of refinement. 

            \begin{equation}
                \label{equ:sfc-mort2d}
                S_{\mathrm{mort},2d} = \left( 0 \to 1 \to 2 \to 3 \right)
            \end{equation}

            \begin{figure}[!htbp]
                \centering
                \foreach \i in {0,1,2} {
                    \begin{subfigure}[b]{.3\textwidth}
                        \centering
                        \begin{tikzpicture}
                            \begin{scope}[colorD,line width=0.6pt]
                                \input{gen/tr-layer\i}
                            \end{scope}
                            \begin{scope}[line width=0.6pt]
                                \foreach \n in {0,...,\i} {
                                    \ifnum \i=\n
                                    \else
                                        \input{gen/tr-layer\n}
                                    \fi
                                }
                            \end{scope}
                            \begin{scope}[colorA]
                                \input{gen/tr-mort-l\i}
                            \end{scope}
                            \draw[line width=1.3pt] (0,0) rectangle (4,4); 
                        \end{tikzpicture}
                        \caption{Level \i}
                        \label{fig:sfc-morton-l\i}
                    \end{subfigure}%
                }
                \caption{Refinement of the Morton curve, with refinement steps shown in red.}
                \label{fig:sfc-morton}
            \end{figure}


        % subsubsection tftt-sfc (end)

        \subsubsection{The Hilbert Curve}
            \label{sec:tftt-hilb}

            The Hilbert Curve was proposed by David Hilbert in 1891 as a curve that guaranteed that sequential cells would always be neighbours. This removes any possibility of complete separation of the cells in a processor unit, and can be represented using the notation described above with the addition of an orientation property $\mathcal{C}\acc\textproc{orient}$, using the notation introduced by Bader \cite{bader2013} in Chapter 3.1.

            \begin{equation}
                S_{\mathrm{hilb,2d}}\left(\mathcal{C}\acc\textproc{orient}\right) =
                \begin{cases}
                    \left( 0 \to 2 \to 3 \to 1\right) & \qif \mathcal{C}\acc\textproc{orient}=H \\
                    \left( 3 \to 1 \to 0 \to 2\right) & \qif \mathcal{C}\acc\textproc{orient}=C \\
                    \left( 0 \to 1 \to 3 \to 2\right) & \qif \mathcal{C}\acc\textproc{orient}=A \\
                    \left( 3 \to 2 \to 0 \to 1\right) & \qif \mathcal{C}\acc\textproc{orient}=B
                \end{cases}
            \end{equation}

            On refinement, the orientation of child cells $\mathcal{C}\acc\mathcal{K}_c\acc\textproc{orient}$ as shown in Table~\ref{tab:hilb-Dc} is a function of the parent orientation $\mathcal{C}\acc\textproc{orient}$ using the production rules given by Bader \cite{bader2013} in a slightly adapted form. The change in orientation can be seen in Figure~\ref{fig:sfc-hilbert} as rotations of the original shape. 

            \begin{table}[!htbp]
                \centering
                \captionsetup{width=0.8\textwidth}
                \caption{Lookup table for child orientation $\mathcal{C}\acc\mathcal{K}_c\acc\textproc{orient}$, as a function of the parent orientation $\mathcal{C}\acc\textproc{orient}$}
                \label{tab:hilb-Dc}
                \begin{tabularx}{5cm}{l>{\raggedright}X*{4}{c}}
                    \toprule
                    &   & \multicolumn{4}{c}{$\mathcal{C}\acc\textproc{orient}$} \\ \cmidrule{3-6}
                    & $c$   & $H$    & $C$    & $A$    & $B$    \\ \midrule
                    & $0$   & $A$    & $C$    & $H$    & $B$    \\
                    & $1$   & $B$    & $C$    & $A$    & $H$    \\
                    & $2$   & $H$    & $A$    & $C$    & $B$    \\
                    & $3$   & $H$    & $B$    & $A$    & $C$    \\ \bottomrule
                \end{tabularx}
            \end{table}

            For both the curve changes and new orientation selection, the Hilbert curve satisfies the requirement that no knowledge of the rest of the tree is required for refinement and coarsening. The Hilbert curve has been defined by a number of independent sources in N dimensions, such as Butz in \cite{butz71}, and can be adapted to the above notation and method of implementation easily retaining similar properties. 

            \begin{figure}[!htbp]
                \centering
                \foreach \i in {0,1,2} {
                    \begin{subfigure}[b]{.3\textwidth}
                        \centering
                        \begin{tikzpicture}
                            \begin{scope}[colorD,line width=0.6pt]
                                \input{gen/tr-layer\i}
                            \end{scope}
                            \begin{scope}[line width=0.6pt]
                                \foreach \n in {0,...,\i} {
                                    \ifnum \i=\n
                                    \else
                                        \input{gen/tr-layer\n}
                                    \fi
                                }
                            \end{scope}
                            \begin{scope}[colorA]
                                \input{gen/tr-hilb-l\i}
                            \end{scope}
                            \draw[line width=1.3pt] (0,0) rectangle (4,4); 
                        \end{tikzpicture}
                        \caption{Level \i}
                        \label{fig:sfc-hilbert-l\i}
                    \end{subfigure}%
                }
                \caption{Refinement of the Hilbert curve, with refinement steps shown in red. }
                \label{fig:sfc-hilbert}
            \end{figure}

        % subsubsection tftt-hilb (end)

    % subsection tftt (end)


    \subsection{Parallel TFTT} % (fold)
        \label{sec:parallel}

        The first stage in adapting the TFTT structure for use in parallel with the MPI library is allowing for only subset of the full domain to exist. 

        The constraint is imposed that the subset of the tree present on a process must for a contiguous section of the space filling curve. Rank zero's first cell is the first cell of the global tree, and the last cell of  rank $W-1$ is the last cell of the global tree. 

        Computational load on each process $p$ taken to be equivalent to the number of leaves it computes over $\eval{\abs{\mathbb{L}}}_p$. Hence the condition for a perfectly balanced load is for each process' cell count to equal the mean.

        Refinement propagation as described in Section~\ref{sec:orthotree-refprop} is relaxed outside of the active area to a propagation length $P=1$. Using $P=0$, whilst possible in theory, leads to more complex maintenance of the SFC outside the active region, which itself makes the later moving of cells along the curve between processes hard. 

        Pointers are stored with the tree root to the first and last cells in the active range. This allows simple iteration over the sub-domain. In the context of a process, the leaves set $\mathbb{L}$ refers only to leaves currently active on that rank.

    % subsection partftt (end)


    \subsection{Global Identifiers} % (fold)
        \label{sec:globalid}

        To enable inter-process communication, a cell identifier format is required that is guaranteed to be unique within the tree. Furthermore, the identifier must be constant for the same cell existing on multiple processes.

        The identifier of a cell is accessed as $\mathcal{C}\acc\textproc{ident}$. Two functions are required for finding (\ref{fun:find}) and inserting (\ref{fun:insert}) the cell with a given identifier $\lambda$ into the tree.

        \begin{align}
            \label{fun:find}
            \textproc{Find}(\lambda) \mapsto \mathcal{C} \\
            \label{fun:insert}
            \textproc{Insert}(\lambda) \mapsto \mathcal{C}
        \end{align}

        The implementation chosen for this project encodes both the level and location of the cell as an unsigned integer, hence uniquely identifying it within the entire tree, and allowing logarithmic lookup and insertion times.

        Retrieving the level, child and parent identifiers, or the child index of the cell is done with bitwise arithmetic. The most significant byte of the integer encodes the level. The remainder of the bits encodes the child orthant for each successive step down the tree with the highest level being in the least significant bits. The number of bits needed to encode an orthant is equal to the number of dimensions of the problem. Using a 64 bit integer this allows for a maximum tree depth of 28 levels in a quadtree, or 18 octree levels.

    % subsection globalid (end)


    \subsection{Ghosts and Borders} % (fold)
        \label{sec:ghostsandborders}

        For each process near its boundaries there are cells who require the data from poisson neighbours outside the tree of the process. These are known as ghost cells, and in order to solve in parallel their values must be retrieved at each iteration. For a process $x$ the set of ghost cells whose rank is another process $y$ is written as $\mathbb{G}_y$.

        Each process also stores the set of cells it owns, who are ghost cells of foreign processes. These are called the border cells, and for a process $x$ the set of border cells to another process $y$ is written as $\mathbb{B}_y$.

        A good space filling curve, such as the Hilbert Curve, leads to process' cells being closely grouped and close to square, for example the 3 processes in Figure~\ref{fig:borderline} are grouped reasonably well with few peninsulas.

        \begin{figure}[!htbp]
            \input{method/gen/borderline.tex}
            \caption{Border cells for 3 processes}
            \label{fig:borderline}
        \end{figure}

        For rank zero, there are ghost cells on both of the other processes as shown in Figure~\ref{fig:borders-r0}.

        \begin{figure}[!htbp]
            \input{method/gen/ghosts-r0.tex}
            \caption{Ghost cells for rank 0}
            \label{fig:borders-r0}
        \end{figure}

        A highly desirable property of the border and ghost sets that greatly simplifies the retrieval of ghost cell data is that for any two processes $x$ and $y$, $\mathbb{G}_y$ on $x$ is exactly the same as $\mathbb{B}_x$ on $y$. In order to guarantee that property the sets are kept sorted according the the global identifier.

        Individual processes do not have enough information to generate their own ghost sets. As a result, the ghost sets for all processes is transferred with the initial cell distribution as outlined in Section~\ref{sec:distribution}. However, knowledge of a processes own cell and ghost sets is sufficient to generate the border set using the method in Algorithm~\ref{alg:borders-gen}.

        \begin{algorithm}[!htbp]
            \caption{Building the border set on process $p$}
            \label{alg:borders-gen}

            \begin{algorithmic}
                \Require A complete ghost set $\mathbb{G}$ for the process $p$.
                \Statex
                \State $\mathbb{B} \gets \emptyset$
                \ForEach {ghost cell $\mathcal{G} \in \mathbb{G}$}
                    \ForEach {poisson neighbour $\mathcal{P} \in \mathcal{G}\acc\vect{\mathcal{P}}$}
                        \If {$\mathcal{P}\acc\textproc{rank} = p$}
                            \State $\mathbb{B}_{\mathcal{G}\acc\textproc{rank}} \gets \mathcal{P}$
                        \EndIf
                    \EndFor
                \EndFor
            \end{algorithmic}
        \end{algorithm}

    % subsection ghostsandborders (end)


    \subsection{Distribution} % (fold)
        \label{sec:distribution}

        Initial distribution is performed as a single process. The tree is refined to its initial mesh, typically according the the known geometry of the problem. The number of cells to be allocated to each process is calculated by dividing the cell count for the initial tree by the number of processes as derived in Section~\ref{sec:parallel}. The procedure in Algorithm~\ref{alg:distrib-assign} then iterates over the space filling curve, setting cells to the current value of a rank counter and incrementing the counter when the processes cell count is reached.

        \begin{algorithm}[!htbp]
            \caption{Building the border set on process $p$}
            \label{alg:distrib-assign}

            \begin{algorithmic}
                \Require An initialised complete tree $\mathbb{L}$
                \Statex
                \State $\bar{c} \gets \frac{\abs{\mathbb{L}}}{\abs{\mathbb{W}}}$ \Comment {Cells per rank}
                \State $\rho \gets 0$ \Comment {Rank counter}
                \State $c \gets \bar c$ \Comment {Cell count remaining for the current rank}
                \ForEach {cell $\mathcal{C} \in \mathbb{L}$ in SFC order}
                    \State $\mathcal{C}\acc\textproc{rank} \gets \rho$
                    \State $c \gets c-1$
                    \If {c = 0} \Comment {Step onto the next rank}
                        \State $\rho \gets \rho+1$
                        \State $c \gets \bar c$
                    \EndIf
                \EndFor
            \end{algorithmic}
        \end{algorithm}

        Since it is not possible for a process to determine its own set of ghost cells without more knowledge of the tree, the starting process then generates all the ghost sets for every rank by using the poisson neighbourhood.

        \begin{algorithm}[!htbp]
            \caption{Generating the ghost sets for all processes}
            \label{alg:distrib-ghosts}

            \begin{algorithmic}
                \Require An initialised complete tree $\mathbb{L}$, with cell ranks assigned for every leaf.
                \Ensure A complete ghost set $\mathbb{G}_{\rho\gets b}$, for every pair of processes $\rho$ and $b$
                \Statex
                \State $\mathbb{G} \gets \emptyset$
                \ForEach {leaf $\mathcal{C} \in \mathbb{L}$}
                    \ForEach {poisson neighbour $\mathcal{P} \in \mathcal{C}\acc\vect{\mathcal{P}}$}
                        \If {$\mathcal{P}\acc\textproc{rank} \neq \mathcal{C}\acc\textproc{rank}$}
                            \State $G_{\mathcal{C}\acc\textproc{rank}\gets\mathcal{P}\acc\textproc{rank}} \gets \mathcal{P}$
                        \EndIf
                    \EndFor
                \EndFor
            \end{algorithmic}
        \end{algorithm}

        The tree is then serialised into a list for every process $\vect{N}_p=\{\lambda,\rho\}^n$ containing pairs of cell identifiers $\lambda$ and ranks $\rho$ referring to either an active cell or a ghost cell of the target process. These are sent to the processes, which unpack them according to the logic in Algorithm~\ref{alg:distrib-unpack}.

        \begin{algorithm}[!htbp]
            \caption{Building the subset of the tree on process $p$}
            \label{alg:distrib-unpack}

            \begin{algorithmic}
                \Require A list $\vect{\hat N}=\{\lambda,\rho\}^n$ containing the cells required by this process.
                \Statex
                \State $\mathbb{G} \gets \emptyset$ \Comment{Ghost set is initially empty}
                \ForEach {packed cell $\{\lambda,\rho\} \in \vect{\hat N}$}
                    \State $\mathcal{C} \gets \textproc{Insert}(\lambda)$ \Comment{$\mathcal{C}$ is a temporary cell reference}
                    \State $\mathcal{C}\acc\textproc{rank} \gets \rho$
                    \If {$\rho \neq p$} \Comment {$\mathcal{C}$ must be a ghost if its rank is not the current process}
                        \State $\mathbb{G}_\rho \gets \mathcal{C}$
                    \EndIf
                \EndFor
            \end{algorithmic}
        \end{algorithm}

        Finally, each process generates its own border set $\mathbb{B}$ using the procedure in Algorithm~\ref{alg:borders-gen}.

    % subsection distribution (end)


    \subsection{Ghost Synchronisation} % (fold)
        \label{sec:ghostsync}

        With each iteration, the data for each processes ghost cells becomes out of date. Synchronisation is used at the end of every iteration to renew this data.

        Since it is required once per iteration, ghost synchronisation is by far the most common parallel operation required. The set up described previously in Section~\ref{sec:ghostsandborders} is designed to minimise this process. By making use of the equivalence of the ghost and border sets for two processes, the only information transfer required is the data from the border cells.

        Without compression, Algorithm~\ref{alg:sync-sendrecv} is therefore the smallest transfer of information possible for this stage. Without knowledge of the contents of the data, the worst case must be assumed that $\mathcal{C}\acc\textproc{data}$ is uniformly distributed and so no compression is possible. 

        \begin{algorithm}[!htbp]
            \caption{Synchronisation}
            \label{alg:sync-sendrecv}

            \begin{algorithmic}
                \ForEach {process boundary $b \in \mathbb{W} \setminus p$}
                    \State $\vect{\Phi} \gets \emptyset$
                    \ForEach {border cell $\mathcal{B}_n \in \mathbb{B}_b$}
                        \State $\Phi_n \gets \mathcal{B}_n\acc\textproc{data}$
                    \EndFor
                    \Send $\vect{\Phi} \dra p_b$
                \EndFor
                \Statex
                \ForEach {process boundary $b \in \mathbb{W} \setminus p$}
                    \Recv $\hat \Phi \dla p_b$

                    \ForEach {ghost cell $\mathcal{G}_n \in \mathbb{G}_b$}
                        \State $\mathcal{G}_n\acc\textproc{data} \gets \Phi_n$
                    \EndFor
                \EndFor
            \end{algorithmic}
        \end{algorithm}

        Further small improvements are made by noting that the length of the vector $\abs{\vect{\Phi}} = \abs{\mathbb{B}_b}$ for each boundary, and so this memory block can be reused to save the cost of repeated allocations.

    % subsection ghostsync (end)


    \subsection{Relaxation in Parallel} % (fold)
        \label{sec:parrelax}

        The relaxation method of Section~\ref{sec:relaxation} can now be executed in parallel, using the adapted loop shown in Algorithm~\ref{alg:parrelax}. Every iteration, ghost data must first be synchronised. The relaxation stage then remains unchanged. The maximum residual on every process must then be merged on rank zero, before the largest residual from any process is broadcast back to the world.

        \begin{algorithm}[!htbp]
            \caption{Relaxation in Parallel, for all processes.}
            \label{alg:parrelax}

            \begin{algorithmic}
                \Ensure {Problem has converged}
                \Repeat
                    \State \Call{syncGhosts}{~}
                    \ForEach {leaf $\mathcal{C} \in \mathbb{L}$}
                        \State \Call{relax}{$\mathcal{C}$}
                    \EndFor
                    \State $r \gets \max\limits_{\mathcal{C}\in\mathbb{L}}\ \textproc{residual}(\mathcal{C})$
                    \Statex
                    \State \begin{tabularx}{0.8\textwidth}{XX}
                        $\textbf{if}\ p=0$ & $\textbf{else}$ \\
                        $\qquad\textbf{reduce}\ \hat r \gets \max\qquad\dla$ & $\qquad\textbf{send}\ r$ \\
                        $\qquad\textbf{broadcast}\ \hat r\qquad\qquad\dra$ & $\qquad\textbf{recv}\ \hat r$
                    \end{tabularx}
                    \State $\textbf{end if}$
                \Until {$\hat r < \epsilon$}
                \Statex
            \end{algorithmic}
        \end{algorithm}

        In practice, the residual doesn't need to be calculated at every iteration and significant savings can be made by calculating it as infrequently as possible. 

    % subsection parrelax (end)


    \subsection{Rebalancing} % (fold)
        \label{sec:rebalancing}

        As identified in Section~\ref{sec:loadbalancing}, a key factor in the performance of distributed methods is how evenly the computational load is spread between processes. If the mesh is changed then the loading is likely to become unbalanced, and rebalancing is required to rectify this. 

        Rebalancing is achieved by calculating the average number of cells per processor, and the movement of cells between processors required to achieve a perfect balance. Since a processes cells are contiguous along the space filling curve, cells can only be passed to the next or previous rank. The process at rank 0 starts with the first cell of the global curve and the process at the ultimate rank ends with the last. Regardless of the dimension of the problem, the space filling curve reduces it to one dimension. A further assumption is made that the number of cells being passed is small compared to the cell count for a process.

        In this way, the rebalancing of the tree, with the exception of the calculations for the pass counts, requires no knowledge of the full tree, only the list of cells being passed to/from the left/right processor.

        As a graphical demonstration of the rebalancing, 20 cells will be transferred from rank 0 to rank 1, starting from the mesh shown in Figure~\ref{fig:rebalance-init}.

        \begin{figure}[!htbp]
            \input{method/gen/init.tex}
            \caption{The starting conditions for the rebalancing example}
            \label{fig:rebalance-init}
        \end{figure}

        Rebalancing is split into the following subroutines: Balance Calculations, updating cell ranks, notifying rank changes, transferring cells, inserting new cells and updating the ghost and border cell sets. These are shown as an activity diagram in Figure~\ref{fig:rebalance-overview}, showing the concurrency of the processes.

        \begin{figure}[!htbp]
            \input{method/moveCells_ad}
            \caption{Activity Diagram of the rebalancing procedure for any three adjacent processes. MPI operations are shown in blue.}
            \label{fig:rebalance-overview}
        \end{figure}


        \subsubsection{Balance Calculation} % (fold)
            \label{sec:rebalancing-calc}

            The cell counts $\vect{c}$ from each node are gathered on rank zero. Balancing is determined necessary based on a parameter $c_{crit}$ if $\norm{\vect{c}}>c_{crit}$. Algorithm~\ref{alg:rebalance-calculatepassing} is then sufficient to determine the number of cells $\Delta$ each process passes left and right to balance every process to the average cell count $\bar c$. A negative value of $\Delta$ gives a cell count being received.

            The loop in Algorithm~\ref{alg:rebalance-calculatepassing} can be reformulated as a proof by induction that the result is the minimum $\Delta$ satisfying the conditions imposed and $\abs{\mathbb{L}}_p=\bar c$ for all $p$.

            \begin{algorithm}[!htbp]
                \caption{Rebalancing Calculations}
                \label{alg:rebalance-calculatepassing}

                \begin{algorithmic}
                    \Ensure For each process $p \in \mathbb{W}$ a pair of cell pass counts $\Delta_p = \{l,r\}$ where $l$ and $r$ are the number of cells to pass left and right respectively.
                    \Statex
                    % \Gather $\vect{c} \dla$ \Call{CellCount}{$p$}
                    \Gather $\vect{c} \dla \abs{\mathbb{L}}_p $
                    \ForEach {process $p \in \mathbb{W}$}
                        \State $l_p \gets -r_{p-1}$
                        \State $r_p \gets c_p - l_p - \bar{c}$
                    \EndFor
                \end{algorithmic}
            \end{algorithm}

            Each process then receives from rank zero the two values in $\Delta_p$ which are enough to fully describe the following cell movements.

        % subsubsection rebalancing-calc (end)


        \subsubsection{Update Cell Ranks} % (fold)
            \label{sec:rebalancing-updatecellranks}

            Based on the movement amount $\Delta$ each process marks the cells to be moved with their new rank, storing the set of changes that would affect the ghost cells of other processes in order to notify them of the change in the next phase of rebalancing in Section~\ref{sec:rebalancing-notifyrank}. The processes that need to be notified of changes is known by using the set of border cells $\mathbb{B}$. The process receiving the cells does not need to be notified of changes, as this data will be transmitted as part of the send sets in Section~\ref{sec:rebalancing-gensendset}.

            In the example case, the cells that are currently on rank 0 but will have their ranks updated to equal 1 are shown in red in Figure~\ref{fig:rebalance-ranks}.

            \begin{figure}[!htbp]
                \input{method/gen/overlap.tex}
                \caption{Example mesh, with 20 cells being marked to be moved from rank 0 to rank 1}
                \label{fig:rebalance-ranks}
            \end{figure}

            \begin{algorithm}[!htbp]
                \caption{Updating Cell Ranks}
                \label{alg:rebalance-updateranks}

                \begin{algorithmic}
                    \Require Number of cells to pass left and right $\Delta = \{\Delta_l,\Delta_r\}$
                    \Ensure For each border $b$, a set $\vect{N}_b \in \{\lambda,r\}^n$ of pairs of cell identifiers $\lambda$ and new rank numbers $r$.
                    \Statex
                    \State $\vect{N} \gets \emptyset$
                    \ForEach {cell $\mathcal{C} \in \{\mathbb{L} : \text{in first }\Delta_l\} $}
                        \Comment{For right, $\mathcal{C} \in \{\mathbb{L} : \text{in last }\Delta_r\} $}
                        \State $\mathcal{C} \acc \textproc{rank} \gets p_{left}$
                        \ForEach {process border $b \in \mathbb{W} \setminus \{p, p_{left}\}$}
                            \If {$\mathcal{C} \in \mathbb{B}_b$}
                                \State $\vect{N}_b \gets \{\mathcal{C} \acc \textproc{ident} , p_{left}\}$
                            \EndIf
                        \EndFor
                    \EndFor
                \end{algorithmic}
            \end{algorithm}

            The routine in Algorithm~\ref{alg:rebalance-updateranks} is repeated for the cells to move right, using the same sets $\vect{N}_b$.

            In the example case, the only process not involved in the transfer already is the one at rank 2. The cells currently on rank 0, but being transferred to rank 1, that border it form the set $\vect{N}_2$ shown in Figure~\ref{fig:rebalance-notify}.

            \begin{figure}[!htbp]
                \input{method/gen/ghostnotify.tex}
                \caption{The example mesh, with the ghost cells of rank 2 whose rank will change following the rebalancing highlighted}
                \label{fig:rebalance-notify}
            \end{figure}

        % subsubsection rebalancing-updatecellranks (end)


        \subsubsection{Notifying Rank Changes} % (fold)
            \label{sec:rebalancing-notifyrank}

            The rank change lists stored in the previous section are now sent. Each process then receives all the changes relevant to its ghosts according to Algorithm~\ref{alg:rebalance-notifyranks}.

            This rank change stage needs to occur before the cells are moved to the new process, as the receiving process is not guaranteed to have the relevant border data required.

            \begin{algorithm}[!htbp]
                \caption{Notifying Cell Rank Changes}
                \label{alg:rebalance-notifyranks}

                \begin{algorithmic}
                    \Require For each border $b$, a set $\vect{N}_b \in \{\lambda,\rho\}^n$ of pairs of cell identifiers $\lambda$ and new rank numbers $\rho$.
                    \Statex
                    \ForEach {process border $b \in \mathbb{W} \setminus p$}
                        \Send $N_b \dra p_b$
                    \EndFor
                    \Statex
                    \ForEach {process border $b \in \mathbb{W} \setminus p$}
                        \Recv $\hat N_b \dla p_b$
                        \ForAll {$\{\lambda,\rho\} \in \hat N_b$}
                            \State $\mathcal{C}\gets\textproc{Find}(\lambda)$
                            \State $\mathcal{C}\acc\textproc{rank} \gets \rho$
                        \EndFor
                    \EndFor
                \end{algorithmic}
            \end{algorithm}

        % subsubsection rebalancing-notifyrank (end)


        \subsubsection{Generate Send Sets} % (fold)
            \label{sec:rebalancing-gensendset}

            After notifying the foreign processes of rank changes, each process then generates the set of cell required to be sent. In addition to the cells being moved, cells in their poisson neighbourhoods not on the rank of the receiving process must also be included in the sets as seen in Figure~\ref{fig:rebalance-transfer}.

            \begin{figure}[!htbp]
                \input{method/gen/Tr.tex}
                \caption{The example mesh, with the cells of $T_r$ highlighted}
                \label{fig:rebalance-transfer}
            \end{figure}

            \begin{algorithm}[!htbp]
                \caption{Generate Send Sets}
                \label{alg:rebalance-gensendsets}

                \begin{algorithmic}
                    \Require Number of cells to pass left $\Delta_l$
                    \Ensure A set of packed cells $\vect{T}_l \in \{\lambda, \rho, \phi\}^n$ containing the cell's identifiers $\lambda$, rank $\rho$ and data $\phi$.
                    \Statex
                    \State $\vect{T}_l \gets \emptyset$
                    \ForEach {cell $\mathcal{C} \in \{\mathbb{L} : \text{in first }\Delta_l\} $}
                        \Comment{If sending right, $\mathcal{C} \in \{\mathbb{L} : \text{in last }\Delta_r\} $}
                        \State $T_l \gets \{\mathcal{C}\acc\textproc{ident}, \mathcal{C}\acc\textproc{rank}, \mathcal{C}\acc\textproc{data}\}$

                        \ForEach {cell $\mathcal{P} \in \mathcal{C}\acc\vect{\mathcal{P}}$}
                            \Comment{$\mathcal{C}\acc\vect{\mathcal{P}}$ is the poisson neighbours of $\mathcal{C}$}
                            \If {$\mathcal{P}\acc\textproc{rank} \neq p_{left}$}
                                \State $T_l \gets \{\mathcal{P}\acc\textproc{ident}, \mathcal{P}\acc\textproc{rank}, \mathcal{P}\acc\textproc{data}\}$
                            \EndIf
                        \EndFor
                    \EndFor
                \end{algorithmic}
            \end{algorithm}

            The two sets $T_l$ and $T_r$ are then transmitted left and right respectively, and the corresponding sets from the foreign processes $U_l$ and $U_r$ are received.

            \begin{algorithm}[!htbp]
                \caption{Send Sets}
                \label{alg:rebalance-sendsets}

                \begin{algorithmic}
                    \Require A set of packed cells $\vect{T}_l \in \{\lambda, \rho, \phi\}^n$ containing the cell's identifiers $\lambda$, rank $\rho$ and data $\phi$.
                    \Statex
                    \Send $\vect{T}_l \dra p_{left} \qquad\ \,;\qquad \algorithmicsend\ \vect{T}_r \dra p_{right}$
                    \Recv $\vect{U}_r \dla p_{right} \qquad;\qquad \algorithmicrecv\ \vect{U}_l \dla p_{left}$
                \end{algorithmic}
            \end{algorithm}

            The combined set $\vect{U}=\vect{U}_l\cup\vect{U}_r$ now contains all the additional information required by the process that wasn't available prior.

        % subsubset rebalancing-gensendset (end)


        \subsubsection{Insert Cell Set} % (fold)
            \label{sec:rebalancing-insertcells}

            Each process then inserts the received cells in $\vect{U}$ and calculates the poisson neighbourhood. All the new cells must be inserted before calculating poisson neighbourhoods, as the correct neighbourhood may include new cells that wouldn't exist prior.

            \begin{algorithm}[!htbp]
                \caption{Insert Received Cells}
                \label{alg:rebalance-insertset}

                \begin{algorithmic}
                    \Require A set of received packed cells from the right $\vect{U} \in \{\lambda, \rho, d\}^n$ containing the cell's identifiers $\lambda$, rank $\rho$ and data $\phi$.
                    \Statex
                    \State $\vect{\Gamma} \gets \emptyset$ \Comment{Cache the cells corresponding to $\vect{U}$}
                    \ForEach {packed cell $\{\lambda, \rho, \phi\} \in \vect{U}$}
                        \State $\mathcal{C} \gets \Call{Insert}{\lambda}$
                        \State $\mathcal{C}\acc\textproc{rank} \gets \rho \qquad;\qquad \mathcal{C}\acc\textproc{data} \gets \phi$
                        \State $\vect{\Gamma} \gets \mathcal{C}$
                    \EndFor
                    \Statex
                    \ForEach {cell $\mathcal{C} \in \vect{\Gamma}$}
                        \State $\mathcal{C}\acc\{\vect{\mathcal{P}}, \vect{b}, \alpha \} \gets \textproc{CalcPoisCoefs}(\mathcal{C})$
                    \EndFor
                \end{algorithmic}
            \end{algorithm}

        % subsubsection rebalancing-insertcells (end)


        \subsubsection{Regenerate Ghosts} % (fold)
            \label{sec:rebalancing-regenghosts}

            The subset of the tree in each process now shows the completed transfer as in Figure~\ref{fig:rebalance-final} for the example case. The ghost and border sets are now outdated however, so must be amended.

            \begin{figure}[!htbp]
                \input{method/gen/result.tex}
                \caption{The rebalanced example mesh}
                \label{fig:rebalance-final}
            \end{figure}


            Although enough information exists to work out the changes required to be made to the border and ghost sets, it is much simpler in practice to reconstruct them completely. Since rebalancing is performed irregularly, the performance cost is negligible.

            The method for reconstruction is equivalent to Algorithm~\ref{alg:distrib-ghosts}, but since all cells in $\mathbb{L}$ have rank $p$ the result is the ghost set for the current context. Border cells are regenerated exactly as in Algorithm~\ref{alg:borders-gen}.

        % subsubsection rebalancing-regenghosts (end)

    % subsection rebalancing (end)

% section method (end)


\section{Proposals for Future Work} % (fold)
    \label{sec:future-work}

    Routines for the next stage of the project have been considered and are summarised below. 

    \subsection{Refinement Propagation in Parallel} % (fold)
        \label{sec:parprop}

        When adapting the local mesh on a process, refinement propagation will often reach the boundary to a foreign process. In order to correctly maintain the desired propagation level, interprocess communication is required. 

        The basis for the method is the addition of "propagation vectors" to border cells, encoding the tree depth and remaining propagation length in each of the orthonormal directions. During refinement propagation, reaching a process boundary in the direction of a foreign process will instead store the vector and stop the propagation. If the border cell is refined as part of the propagation, the border cell set must be reconstructed. 

        These are then transmitted, taking advantage of ghost-border equivalence to minimise data transfer, using the method already used for ghost synchronisation in Section~\ref{sec:ghostsync}. The vectors are then applied the receiving process, by continuing the propagation. 

        If the vector level is greater than the current depth of the ghost cell receiving it, this means that ghost is being refined. The cell must be refined on the receiving process, and the ghost cell set reconstructed. Since the corresponding border set has had the same change applied to it, ghost-border equivalence is maintained. 


        \subsubsection{Process Re-entry} % (fold)
            \label{sec:parprop-reentry}

            One common occurrence when distributing according to the Hilbert curve is the presence of "peninsulas" along the process boundaries. An example can be seen in Figure~\ref{fig:borderline} from Section~\ref{sec:ghostsandborders}, where a region of cells on rank one are bordered on three sides by cells on rank zero. 

            Refinement propagation as proposed above would work on these peninsulas, but would result in the passing through the of propagation vectors from rank zero back to itself. Since this requires a second stage of propagation, it is desirable this should be avoided.

            In order to alleviate this issue, processes propagating onto border cells can no longer stop at that point. Instead they continue as long as they remain within the ghost cells of the process. It is not possible outside the region of the ghost cells to know the level of cells at that point, so propagation is not possible. 

            Since the propagation process from a vector is initiated started from a ghost cell whose foreign rank is known, it is sufficient for receiving processes to end propagation if they return to a border with the process the vector originates from. 

            Although greatly complicating the method, the reduction in the interprocess messages required makes re-entry avoidance 

        % subsubsection parprop-reentry (end)

    % subsection parprop (end)


    \subsection{Initial Construction in Parallel} % (fold)
        \label{sec:parinit}

        Typically the initial construction of the mesh refines to a globally known geometry. As such, it is feasible that the mesh could be constructed in parallel. For highly refined meshes, this is desirable as the initial construction can be slow, and the amount of data to be subsequently distributed to the processes large. 

        \subsubsection{Staggered Construction}
            \label{sec:parainit-staggered}

            A simple approach would be to refine the mesh to a number of levels below the desired maximum depth before distributing. After distributing each process then refines the remaining stages itself, before the whole system is rebalanced. 

            If there are too many additional refinement levels, difficulties may be encountered in rebalancing where the assumption was made that changes are small. This can be rectified by including multiple rebalancing stages.

            This method relies on the implementation of the parallel refinement methods given in Section~\ref{sec:parprop}, but is otherwise possible with the current functionality of the library. 

        % subsubsection parinit-staggered (end)


        \subsubsection{Bottom-Up Construction}
            \label{sec:parainit-bottomup}

            A method proposed by Sundar et al in \cite{sundar2008} is to first identify the locations within the domain where the most refined cells are known to appear. This subset of the final leaves of the tree is then distributed and the mesh constructed on each process to include a number of these. 

            This would be possible to implement with the SFC additions to the structure, as cells can be ordered along the Hilbert curve based on their location and depth, without the need to construct the mesh or the full SFC.

            To take the trivial top level quadtree case, it's known that any cell located in upper-left quadrant of the domain must appear in the Hilbert curve after any cell in the bottom-left quadrant. Similar results are possible for any depth. 

            Refinement propagation in parallel, as proposed in Section~\ref{sec:parprop} would still need to be used to ensure the final mesh obeys the constraints imposed. 
 
        % subsubsection parinit-bottomup (end)

    % subsection parinit (end)

% section future-work (end)


\section{Results} % (fold)
    \label{sec:results}

    \subsection{Solving Poisson's Equation in Parallel} % (fold)
        \label{sec:results-poissons}

        As a test case, Equation~\ref{equ:poisson} was solved with circle being the geometry shown in Figure~\ref{fig:pois-geometry}. The domain boundaries were set to a constant value of zero.

        \begin{equation}
            \laplacian{\Phi}=\begin{cases}
                -1 & \qq{if} \mathcal{C}\acc\textproc{center} \in \text{circle} \\
                0 & \qq{otherwise}
            \end{cases}
            \label{equ:poisson}
        \end{equation}

        \begin{figure}[!htbp]
            \centering
            \begin{tikzpicture}
                \draw[thick,black] (0,0) rectangle (4,4);
                \node[thick,fill=colorA,inner sep=0, minimum size=0.8cm,circle] at (1.2,1.2) {};
            \end{tikzpicture}
            \caption{Hello}
            \label{fig:pois-geometry}
        \end{figure}

        The solution is shown in Figure~\ref{fig:pois-result}. The program was able to converge to the same solution for all configurations attempted, and for arbitrarily high world sizes. 

        \begin{figure}[!htbp]
            \centering
            \input{gen/pois-splot}
            \caption{Surface plot of the final value of $\Phi$ across the domain.}
            \label{fig:pois-result}
        \end{figure}

    % subsection results-poissons (end)


    \subsection{Boundary size for Hilbert Curve}
        \label{sec:results-boundarysize}

        The total size of the boundary layers was tested empirically. A more complex test geometry was created, using the Mandelbrot fractal set. For a range of tree configurations, the mesh was constructed and distributed, recording the size of the ghost set. This was repeated for different positions and scales of the set and averages used.

        By averaging over many tree configurations, it is assumed a relationship can be found for the ghost cell count $G$ as a function of the total cell count $C$ and the world size $W$.

        The ghost cell count increases proportionally with the cell count to the power of $0.4562$, as shown in Figure~\ref{fig:anal-scaling}. The upper limit for the exponent would be the relationship for a uniform mesh. In the simplest case to analyse, where $W$ is a power of two, this is $0.5$. 

        \tikzset{external/export next=false}
        \begin{figure}[!htbp]
            \centering
            \input{results/gen2/mbrot-scale}
            \caption{Ghost cell count against cell count for a range of world sizes. }
            \label{fig:anal-scaling}
        \end{figure}

        Though close, the vertical spacing between lines of world size in Figure~\ref{fig:anal-scaling} are not quite linear in $W$, most visibly the gap from $W=2$ to $W=4$ is noticeably larger. This is explored in more detail in Figure~\ref{fig:anal-borderworldsize}. Significant variations are seen in the test data, in some cases increases the number of processes has the effect of decreasing the total number of ghost cells, though this behaviour is unpredictable and so cannot be taken advantage of. The ghost cell fraction increases as a function of the world size $8.5(W^{0.52}-1.24)$, compared to the uniform mesh case with $W$ being a square number $4(\sqrt{W} - 1)$. 

        \tikzset{external/export next=false}
        \begin{figure}[!htbp]
            \centering
            \input{results/gen2/borderworldsize}
            \caption{Ghost cell fraction against world size for the tree configurations refined to a maximum depth 12. The ghost cell fraction is used to normalise the differences in total cell counts between the test cases.}
            \label{fig:anal-borderworldsize}
        \end{figure}

        In summary, it was found that the typical ghost cell count was approximately given by Equation~\ref{equ:ghostcount}. Different meshes produced considerable variations, but on average the Hilbert curve produces results that are not significantly worse than the theoretical limits taken from uniform mesh distributions. Given the complexity of the meshes involved, these results confirm the suitability of the Hilbert curve for use in distributing orthotrees to processes.

        \begin{equation}
            G \approx C^{0.4562} \times 8.5(W^{0.52}-1.24)
            \label{equ:ghostcount}
        \end{equation}

    % subsection results-boundarysize (end)


    \subsection{Structure Overhead} % (fold)
        \label{sec:results-memoryuse}

        Memory overheads for the structure are split across three structures. Each \mintinline{cpp}{TreeCell} structure stores data for an individual cell. Where possible, cell data is shared between siblings of an ortho in the \mintinline{cpp}{TreeGroup} structure. Finally, global properties of the tree are stored in the \mintinline{cpp}{Tree} structure. The outline of these structures can be found in Appendix~\ref{sec:appendix-headers}.

        Table~\ref{tab:results-memusage} contains a rough breakdown of where the memory overhead is introduced. In some cases these are functions of the dimension of the tree, in which case the quadtree values are used. Fundamental type sizes are not fixed by the \CC~standard, instead the common values on modern architectures are used. Totals take into account padding required for structure alignment, and so might not be the sum of previous columns.

        \begin{table}[!htbp]
            \centering
            \caption{Memory overhead within a quadtree structure, measured in bytes.}
            \label{tab:results-memusage}
            \begin{threeparttable}
                \begin{tabular}{@{}l>{\hskip 1cm}ccccc>{\hskip 1cm}c@{}}
                \toprule
                \textbf{Structure}  & Orthotree & FTT & TFTT & Poisson & Parallel & \textbf{Totals} \\ \midrule
                \texttt{TreeCell}   & 9         & 0   & 0    & 137     & 1        & 152    \\ % 152
                \texttt{TreeGroup}  & 24        & 32  & 17   & 0       & 8        & 88     \\ % 88
                \texttt{Tree}       & 32        & 0   & 16   & 0       & $16G$\tnote{1}        & 48     \\ \addlinespace[4mm] \cmidrule{7-7} % \rule{0pt}{8mm}  % 
                \textbf{Sum / cell} & 15        & 8   & 4.25 & 137     & 3        & \textbf{174}    \\ \bottomrule
                \end{tabular}
                \begin{tablenotes}
                    \item[1] Depends on the number of ghost cells $G$. This is small compared to the cell count, so doesn't impact totals (See Section~\ref{sec:results-boundarysize}).
                \end{tablenotes}
            \end{threeparttable}
        \end{table}

        The vast majority of the overhead memory usage therefore comes from the storing of the poisson neighbourhood. The storage requirement added by the parallelization of the structure is just $7.25$ bytes per cell. 

    % subsection results-memoryuse (end)


    % \subsection{Performance against Thread Count} % (fold)
    %     \label{sec:results-performance}

    % % subsection results-performance (end)


    % \subsection{Cluster Operation Above Single Node Memory Limit}
    %     \label{sec:results-memory}

    % subsection results-memory (end)

% section results (end)


\section{Conclusion} % (fold)
    \label{sec:conclusions}

    It has been successfully demonstrated that an adaptive mesh method can be used to solve numeric problems in parallel, in a manner suitable for use on clusters. The developed library is robust, and a clean interface is provided that simplifies development using the structure. 

    The library is efficient, both in memory and computational time. 

    For operations performed on every iteration of the solver, the interprocess communication sends the minimum possible data. Other operations are performed less often, but the information transferred is limited to only the relevant cells for any pair of processes communicating. 

    The use of the Hilbert curve for distribution is computationally simple, and results in process boundary sizes close to theoretical lower bounds. Other properties of the curve, such as remaining bounded within a cell for all its children, make the Hilbert curve an excellent choice for use in the TFTT structure. 

    The structure is only tested on simple scenarios. For comparison to other methods, it would be necessary to implement a fluids solver using the library.

    Further work is required on refining the mesh in parallel, both during initial construction and to adapt to changing problem conditions. A method is presented for the latter, but has not been implemented. 

% section conclusion (end)


\begingroup
\raggedright
\sloppy
\printbibliography[heading=bibintoc]
\endgroup


\clearpage
\appendix

\section{Appendix} % (fold)
    \label{sec:appendix}

    \subsection{Key Source Headers} % (fold)
        \label{sec:appendix-headers}

        % \listoflistings

        \begin{listing}[H]
            \caption{Types Header}
            \label{src:types}
            \inputminted[mathescape,fontsize=\scriptsize]{cpp}{headers/types.h}
        \end{listing}

        \begin{listing}[H]
            \caption{CellRef Header}
            \label{src:cellref}
            \inputminted[mathescape,fontsize=\scriptsize]{cpp}{headers/cellref.h}
        \end{listing}

        \begin{listing}[H]
            \caption{TreeCell Header}
            \label{src:treecell}
            \inputminted[mathescape,fontsize=\scriptsize]{cpp}{headers/treecell.h}
        \end{listing}

        \begin{listing}[H]
            \caption{TreeGroup Header}
            \label{src:treegroup}
            \inputminted[mathescape,fontsize=\scriptsize]{cpp}{headers/treegroup.h}
        \end{listing}

        \begin{listing}[H]
            \caption{Tree Header}
            \label{src:tree}
            \inputminted[mathescape,fontsize=\scriptsize]{cpp}{headers/tree.h}
        \end{listing}

    % subsection appendix-headers (end)


    % \subsection{Poisson Neighbour Interpolation Cases}
    %     \label{sec:appendix-poissoninterp}

    % % subsection appendix-poissoninterp


    \subsection{Risk Assessment Retrospective} % (fold)
        \label{sec:appendix-ra}

        The project was purely computational. Appropriate precautions were taken to avoid the health issues associated with prolongued computer use. Specifically, posture was researched and corrected where necessary at the start of the project.

        Despite precautions, a minor Repetitive Strain Injury (RSI) was experienced in the right wrist, exasperated by intensive sports trainings. On the advice of a physio, further changes were made to computer usage. This included the raising of the right wrist relative to the mouse, and greater use of the keyboard for repeated tasks. With corrections, the issue was resolved and no further problems were encountered. 

    % subsection ra (end)

% section appendix (end)

\end{document}
